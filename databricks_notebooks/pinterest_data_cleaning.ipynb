{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee34f8c1-faed-414d-b04e-0bf3164e5893",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_pin_data(df):\n",
    "    \"\"\"\n",
    "    Performs data transformation on pin data table \n",
    "    - normalises follower count column to be numeric (not letter abbreviations, e.g. k for 1000)\n",
    "    - removes unnecessary pre-amble text from path pin is saved to\n",
    "    - normalises cells with missing information to be represented as null values\n",
    "    - renames index column\n",
    "    - drops duplicate rows\n",
    "    \n",
    "    Returns: cleaned Spark dataframe\n",
    "    \"\"\"\n",
    "    df_pin = df.withColumn(\"follower_count\", when(df.follower_count.endswith(\"k\"),regexp_replace(df.follower_count,\"k\",\"000\")) \\\n",
    "                                                .when(df.follower_count.endswith(\"M\"),regexp_replace(df.follower_count,\"M\",\"000000\")) \\\n",
    "                                                .when(df.follower_count == \"User Info Error\", None)\n",
    "                                                .otherwise(df.follower_count)\n",
    "                                                )\n",
    "    df_pin = df_pin.withColumn(\"follower_count\", df_pin.follower_count.cast(\"integer\"))\n",
    "    df_pin = df_pin.withColumn(\"save_location\", regexp_replace(\"save_location\", \"Local save in \", \"\"))\n",
    "    df_pin = df_pin.withColumn(\"title\", when(df_pin.title == \"No Title Data Available\", None).otherwise(df_pin.title))\n",
    "    df_pin = df_pin.withColumn(\"description\", when(df_pin.description == \"No description available Story format\", None).otherwise(df_pin.description))\n",
    "    df_pin = df_pin.withColumn(\"image_src\", when(df_pin.image_src == \"Image src error.\", None).otherwise(df_pin.image_src))\n",
    "    df_pin = df_pin.withColumn(\"tag_list\", when(df_pin.tag_list == \"N,o, ,T,a,g,s, ,A,v,a,i,l,a,b,l,e\", None).otherwise(df_pin.tag_list))\n",
    "    df_pin = df_pin.withColumn(\"poster_name\", when(df_pin.poster_name == \"User Info Error\", None).otherwise(df_pin.poster_name))\n",
    "    df_pin = df_pin.withColumnRenamed('index', 'ind')\n",
    "    df_pin = df_pin.select(\"ind\", \n",
    "                        \"unique_id\", \n",
    "                        \"title\", \n",
    "                        \"description\", \n",
    "                        \"follower_count\",\n",
    "                        \"poster_name\",\n",
    "                        \"tag_list\",\n",
    "                        \"is_image_or_video\",\n",
    "                        \"image_src\",\n",
    "                        \"save_location\",\n",
    "                        \"category\")\n",
    "    df_pin = df_pin.dropDuplicates()\n",
    "\n",
    "    return df_pin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7b593bb-71a2-4c96-9a85-c82329c8aebb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_geo_data(df):\n",
    "    \"\"\"\n",
    "    Performs data transformation on geo data table \n",
    "    - merges latitude and longitude columns\n",
    "    - casts timestamp column to timestamp format\n",
    "    - drops duplicate rows\n",
    "    \n",
    "    Returns: cleaned Spark dataframe\n",
    "    \"\"\"\n",
    "    df_geo = df.withColumn(\"coordinates\", array(\"latitude\", \"longitude\"))\n",
    "    df_geo = df_geo.drop(\"latitude\", \"longitude\")\n",
    "    df_geo = df_geo.withColumn(\"timestamp\", df_geo[\"timestamp\"].cast(\"timestamp\"))\n",
    "    df_geo = df_geo.dropDuplicates()\n",
    "\n",
    "    return df_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dbfa42c-0910-4fb6-8af6-b161ee8b598a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_user_data(df):\n",
    "    \"\"\"\n",
    "    Performs data transformation on user data table \n",
    "    - merges name columns\n",
    "    - casts dates to timestamp format\n",
    "    - drops duplicate rows\n",
    "    \n",
    "    Returns: cleaned Spark dataframe\n",
    "    \"\"\"\n",
    "    df_user = df.withColumn(\"user_name\", concat_ws(\" \", \"first_name\", \"last_name\"))\n",
    "    df_user = df_user.drop(\"first_name\", \"last_name\")\n",
    "    df_user = df_user.withColumn(\"date_joined\", df_user[\"date_joined\"].cast(\"timestamp\"))\n",
    "    df_user = df_user.select(\"ind\",\n",
    "                            \"user_name\",\n",
    "                            \"age\",\n",
    "                            \"date_joined\")\n",
    "    df_user = df_user.dropDuplicates()\n",
    "\n",
    "    return df_user"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pinterest_data_cleaning",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
